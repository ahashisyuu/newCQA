{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import spacy\n",
    "import json\n",
    "import pandas\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from tqdm import tqdm\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from process_text import process_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "relevance2label = {'Good': 0, 'PotentiallyUseful': 1, 'Bad': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SemEval16or17_sample(filename):\n",
    "    root = ET.parse(filename).getroot()\n",
    "    for thread in root.findall('Thread'):\n",
    "        question = thread.find('RelQuestion')\n",
    "        \n",
    "        q_id = question.get('RELQ_ID')\n",
    "        q_category = question.get('RELQ_CATEGORY')\n",
    "        q_date = question.get('RELQ_DATE')\n",
    "        q_userid = question.get('RELQ_USERID')\n",
    "        q_username = question.get('RELQ_USERNAME')\n",
    "        \n",
    "        q_subject = question.find('RelQSubject').text or ''\n",
    "        q_body = question.find('RelQBody').text or ''\n",
    "        \n",
    "        for relcomment in thread.findall('RelComment'):\n",
    "            c_id = relcomment.get('RELC_ID')\n",
    "            c_date = relcomment.get('RELC_DATE')\n",
    "            c_userid = relcomment.get('RELC_USERID')\n",
    "            c_username = relcomment.get('RELC_USERNAME')\n",
    "            Relevance = relcomment.get('RELC_RELEVANCE2RELQ')\n",
    "            cTEXT = relcomment.find('RelCText').text or ''\n",
    "#             if len(q_subject) == 0 or len(q_body) == 0 or len(cTEXT) == 0:\n",
    "#                 print(c_id, len(q_subject), len(q_body), len(cTEXT))\n",
    "#                 continue\n",
    "            yield [q_id, c_id, q_category, q_subject, q_body, cTEXT, Relevance, q_userid, c_userid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataFrame\n",
    "columns = ['q_id', 'c_id', 'q_category', 'q_subject', 'q_body', 'cTEXT', 'Relevance', 'q_userid', 'c_userid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t\t处理文件：15dev.xml\n",
      "\n",
      "\n",
      "\t\t处理文件：15test.xml\n",
      "\n",
      "\n",
      "\t\t处理文件：15train.xml\n",
      "\n",
      "\n",
      "\t\t处理文件：16dev.xml\n",
      "\n",
      "\n",
      "\t\t处理文件：16test.xml\n",
      "\n",
      "\n",
      "\t\t处理文件：16train1.xml\n",
      "\n",
      "\n",
      "\t\t处理文件：16train2.xml\n",
      "\n",
      "\n",
      "\t\t处理文件：17test.xml\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filepath = '../raw_data'\n",
    "all_samples = {}\n",
    "data_filename_list = os.listdir(filepath)\n",
    "\n",
    "for name in data_filename_list:\n",
    "    print('\\n\\t\\t处理文件：%s\\n' % name)\n",
    "    filename = os.path.join(filepath, name)\n",
    "    samples = SemEval16or17_sample(filename)\n",
    "#     samples = [sample for sample in tqdm(samples)]\n",
    "    all_samples[name] = pandas.DataFrame(columns=columns, data=samples)\n",
    "    all_samples[name].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_id</th>\n",
       "      <th>c_id</th>\n",
       "      <th>q_category</th>\n",
       "      <th>q_subject</th>\n",
       "      <th>q_body</th>\n",
       "      <th>cTEXT</th>\n",
       "      <th>Relevance</th>\n",
       "      <th>q_userid</th>\n",
       "      <th>c_userid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q2481</td>\n",
       "      <td>Q2481_C1</td>\n",
       "      <td>Life in Qatar</td>\n",
       "      <td>from DUBAI to QATAR</td>\n",
       "      <td>i am currently working here in dubai and i got...</td>\n",
       "      <td>If you are single then its ok you can enjoy.</td>\n",
       "      <td>PotentiallyUseful</td>\n",
       "      <td>U8902</td>\n",
       "      <td>U7263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2481</td>\n",
       "      <td>Q2481_C2</td>\n",
       "      <td>Life in Qatar</td>\n",
       "      <td>from DUBAI to QATAR</td>\n",
       "      <td>i am currently working here in dubai and i got...</td>\n",
       "      <td>depends on where the accommodation is.. how ma...</td>\n",
       "      <td>Good</td>\n",
       "      <td>U8902</td>\n",
       "      <td>U604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q2481</td>\n",
       "      <td>Q2481_C3</td>\n",
       "      <td>Life in Qatar</td>\n",
       "      <td>from DUBAI to QATAR</td>\n",
       "      <td>i am currently working here in dubai and i got...</td>\n",
       "      <td>If the company is from Oil and Gas Industry or...</td>\n",
       "      <td>Good</td>\n",
       "      <td>U8902</td>\n",
       "      <td>U2316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q2481</td>\n",
       "      <td>Q2481_C4</td>\n",
       "      <td>Life in Qatar</td>\n",
       "      <td>from DUBAI to QATAR</td>\n",
       "      <td>i am currently working here in dubai and i got...</td>\n",
       "      <td>Transport in the city is a nightmare.</td>\n",
       "      <td>Good</td>\n",
       "      <td>U8902</td>\n",
       "      <td>U5547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q2481</td>\n",
       "      <td>Q2481_C5</td>\n",
       "      <td>Life in Qatar</td>\n",
       "      <td>from DUBAI to QATAR</td>\n",
       "      <td>i am currently working here in dubai and i got...</td>\n",
       "      <td>And life her is so relaxed that bachelors are ...</td>\n",
       "      <td>Bad</td>\n",
       "      <td>U8902</td>\n",
       "      <td>U5547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    q_id      c_id     q_category            q_subject  \\\n",
       "0  Q2481  Q2481_C1  Life in Qatar  from DUBAI to QATAR   \n",
       "1  Q2481  Q2481_C2  Life in Qatar  from DUBAI to QATAR   \n",
       "2  Q2481  Q2481_C3  Life in Qatar  from DUBAI to QATAR   \n",
       "3  Q2481  Q2481_C4  Life in Qatar  from DUBAI to QATAR   \n",
       "4  Q2481  Q2481_C5  Life in Qatar  from DUBAI to QATAR   \n",
       "\n",
       "                                              q_body  \\\n",
       "0  i am currently working here in dubai and i got...   \n",
       "1  i am currently working here in dubai and i got...   \n",
       "2  i am currently working here in dubai and i got...   \n",
       "3  i am currently working here in dubai and i got...   \n",
       "4  i am currently working here in dubai and i got...   \n",
       "\n",
       "                                               cTEXT          Relevance  \\\n",
       "0       If you are single then its ok you can enjoy.  PotentiallyUseful   \n",
       "1  depends on where the accommodation is.. how ma...               Good   \n",
       "2  If the company is from Oil and Gas Industry or...               Good   \n",
       "3              Transport in the city is a nightmare.               Good   \n",
       "4  And life her is so relaxed that bachelors are ...                Bad   \n",
       "\n",
       "  q_userid c_userid  \n",
       "0    U8902    U7263  \n",
       "1    U8902     U604  \n",
       "2    U8902    U2316  \n",
       "3    U8902    U5547  \n",
       "4    U8902    U5547  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_samples['15dev.xml'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15dev.xml\n",
      "15test.xml\n",
      "15train.xml\n",
      "16dev.xml\n",
      "16test.xml\n",
      "16train1.xml\n",
      "16train2.xml\n",
      "17test.xml\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "keys_lists = all_samples.keys()\n",
    "\n",
    "for key in keys_lists:\n",
    "    print(key)\n",
    "    samples = all_samples[key]\n",
    "    samples['cate_index'] = samples['q_category'].apply(lambda x: Qcategory_dic[x])\n",
    "    samples['rel_index'] = samples['Relevance'].apply(lambda x: Relevance_dic[x])\n",
    "    Relevance_dic_v2 = copy.copy(Relevance_dic)\n",
    "    Relevance_dic_v2['Bad'] = 1\n",
    "    samples['Rrel_index'] = samples['Relevance'].apply(lambda x: Relevance_dic_v2[x])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_id                                                      Q2481\n",
      "c_id                                                   Q2481_C2\n",
      "q_category                                        Life in Qatar\n",
      "q_subject                                   from DUBAI to QATAR\n",
      "q_body        i am currently working here in dubai and i got...\n",
      "cTEXT         depends on where the accommodation is.. how ma...\n",
      "Relevance                                                  Good\n",
      "q_userid                                                  U8902\n",
      "c_userid                                                   U604\n",
      "cate_index                                                    9\n",
      "rel_index                                                     0\n",
      "Rrel_index                                                    0\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(all_samples['15dev.xml'].iloc[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15dev.xml\n",
      "15test.xml\n",
      "15train.xml\n",
      "16dev.xml\n",
      "16test.xml\n",
      "16train1.xml\n",
      "16train2.xml\n",
      "17test.xml\n"
     ]
    }
   ],
   "source": [
    "# tokenize (with lemm)\n",
    "import nltk\n",
    "\n",
    "wn_lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "for key in keys_lists:\n",
    "    print(key)\n",
    "    samples = all_samples[key]\n",
    "    \n",
    "    def _tokenizer(x):\n",
    "        if x is None:\n",
    "            return [\"[SEP]\"]*2\n",
    "        sent = nltk.word_tokenize(x.lower())\n",
    "        return [\"[SEP]\"] + sent + [\"[SEP]\"]\n",
    "    \n",
    "    samples['q_sub_token'] = samples['q_subject'].apply(_tokenizer)\n",
    "    samples['q_body_token'] = samples['q_body'].apply(_tokenizer)\n",
    "    samples['cTEXT_token'] = samples['cTEXT'].apply(_tokenizer)\n",
    "\n",
    "    \n",
    "    samples['q_sub_lemma'] = samples['q_sub_token'].apply(lambda tokens: [wn_lemmatizer.lemmatize(x) for x in tokens])\n",
    "    samples['q_body_lemma'] = samples['q_body_token'].apply(lambda tokens: [wn_lemmatizer.lemmatize(x) for x in tokens])\n",
    "    samples['cTEXT_lemma'] = samples['cTEXT_token'].apply(lambda tokens: [wn_lemmatizer.lemmatize(x) for x in tokens])\n",
    "    \n",
    "    def _process_text(x):\n",
    "        if x is None:\n",
    "            return [\"[SEP]\"]*2\n",
    "        sent = process_text(x)\n",
    "        return [\"[SEP]\"] + sent + [\"[SEP]\"]\n",
    "    \n",
    "    samples['q_sub_lemma_pro'] = samples['q_subject'].apply(_process_text)\n",
    "    samples['q_body_lemma_pro'] = samples['q_body'].apply(_process_text)\n",
    "    samples['cTEXT_lemma_pro'] = samples['cTEXT'].apply(_process_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_id</th>\n",
       "      <th>c_id</th>\n",
       "      <th>q_category</th>\n",
       "      <th>q_subject</th>\n",
       "      <th>q_body</th>\n",
       "      <th>cTEXT</th>\n",
       "      <th>Relevance</th>\n",
       "      <th>q_userid</th>\n",
       "      <th>c_userid</th>\n",
       "      <th>cate_index</th>\n",
       "      <th>...</th>\n",
       "      <th>Rrel_index</th>\n",
       "      <th>q_sub_token</th>\n",
       "      <th>q_body_token</th>\n",
       "      <th>cTEXT_token</th>\n",
       "      <th>q_sub_lemma</th>\n",
       "      <th>q_body_lemma</th>\n",
       "      <th>cTEXT_lemma</th>\n",
       "      <th>q_sub_lemma_pro</th>\n",
       "      <th>q_body_lemma_pro</th>\n",
       "      <th>cTEXT_lemma_pro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q2481</td>\n",
       "      <td>Q2481_C1</td>\n",
       "      <td>Life in Qatar</td>\n",
       "      <td>from DUBAI to QATAR</td>\n",
       "      <td>i am currently working here in dubai and i got...</td>\n",
       "      <td>If you are single then its ok you can enjoy.</td>\n",
       "      <td>PotentiallyUseful</td>\n",
       "      <td>U8902</td>\n",
       "      <td>U7263</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[SEP], from, dubai, to, qatar, [SEP]]</td>\n",
       "      <td>[[SEP], i, am, currently, working, here, in, d...</td>\n",
       "      <td>[[SEP], if, you, are, single, then, its, ok, y...</td>\n",
       "      <td>[[SEP], from, dubai, to, qatar, [SEP]]</td>\n",
       "      <td>[[SEP], i, am, currently, working, here, in, d...</td>\n",
       "      <td>[[SEP], if, you, are, single, then, it, ok, yo...</td>\n",
       "      <td>[[SEP], from, dubai, to, qatar, [SEP]]</td>\n",
       "      <td>[[SEP], i, am, currently, working, here, in, d...</td>\n",
       "      <td>[[SEP], if, you, are, single, then, it, ok, yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2481</td>\n",
       "      <td>Q2481_C2</td>\n",
       "      <td>Life in Qatar</td>\n",
       "      <td>from DUBAI to QATAR</td>\n",
       "      <td>i am currently working here in dubai and i got...</td>\n",
       "      <td>depends on where the accommodation is.. how ma...</td>\n",
       "      <td>Good</td>\n",
       "      <td>U8902</td>\n",
       "      <td>U604</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[SEP], from, dubai, to, qatar, [SEP]]</td>\n",
       "      <td>[[SEP], i, am, currently, working, here, in, d...</td>\n",
       "      <td>[[SEP], depends, on, where, the, accommodation...</td>\n",
       "      <td>[[SEP], from, dubai, to, qatar, [SEP]]</td>\n",
       "      <td>[[SEP], i, am, currently, working, here, in, d...</td>\n",
       "      <td>[[SEP], depends, on, where, the, accommodation...</td>\n",
       "      <td>[[SEP], from, dubai, to, qatar, [SEP]]</td>\n",
       "      <td>[[SEP], i, am, currently, working, here, in, d...</td>\n",
       "      <td>[[SEP], depends, on, where, the, accommodation...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    q_id      c_id     q_category            q_subject  \\\n",
       "0  Q2481  Q2481_C1  Life in Qatar  from DUBAI to QATAR   \n",
       "1  Q2481  Q2481_C2  Life in Qatar  from DUBAI to QATAR   \n",
       "\n",
       "                                              q_body  \\\n",
       "0  i am currently working here in dubai and i got...   \n",
       "1  i am currently working here in dubai and i got...   \n",
       "\n",
       "                                               cTEXT          Relevance  \\\n",
       "0       If you are single then its ok you can enjoy.  PotentiallyUseful   \n",
       "1  depends on where the accommodation is.. how ma...               Good   \n",
       "\n",
       "  q_userid c_userid  cate_index  \\\n",
       "0    U8902    U7263           9   \n",
       "1    U8902     U604           9   \n",
       "\n",
       "                         ...                          Rrel_index  \\\n",
       "0                        ...                                   1   \n",
       "1                        ...                                   0   \n",
       "\n",
       "                              q_sub_token  \\\n",
       "0  [[SEP], from, dubai, to, qatar, [SEP]]   \n",
       "1  [[SEP], from, dubai, to, qatar, [SEP]]   \n",
       "\n",
       "                                        q_body_token  \\\n",
       "0  [[SEP], i, am, currently, working, here, in, d...   \n",
       "1  [[SEP], i, am, currently, working, here, in, d...   \n",
       "\n",
       "                                         cTEXT_token  \\\n",
       "0  [[SEP], if, you, are, single, then, its, ok, y...   \n",
       "1  [[SEP], depends, on, where, the, accommodation...   \n",
       "\n",
       "                              q_sub_lemma  \\\n",
       "0  [[SEP], from, dubai, to, qatar, [SEP]]   \n",
       "1  [[SEP], from, dubai, to, qatar, [SEP]]   \n",
       "\n",
       "                                        q_body_lemma  \\\n",
       "0  [[SEP], i, am, currently, working, here, in, d...   \n",
       "1  [[SEP], i, am, currently, working, here, in, d...   \n",
       "\n",
       "                                         cTEXT_lemma  \\\n",
       "0  [[SEP], if, you, are, single, then, it, ok, yo...   \n",
       "1  [[SEP], depends, on, where, the, accommodation...   \n",
       "\n",
       "                          q_sub_lemma_pro  \\\n",
       "0  [[SEP], from, dubai, to, qatar, [SEP]]   \n",
       "1  [[SEP], from, dubai, to, qatar, [SEP]]   \n",
       "\n",
       "                                    q_body_lemma_pro  \\\n",
       "0  [[SEP], i, am, currently, working, here, in, d...   \n",
       "1  [[SEP], i, am, currently, working, here, in, d...   \n",
       "\n",
       "                                     cTEXT_lemma_pro  \n",
       "0  [[SEP], if, you, are, single, then, it, ok, yo...  \n",
       "1  [[SEP], depends, on, where, the, accommodation...  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_samples['15dev.xml'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2index = {key: value+1 for value, key in enumerate(string.ascii_letters + string.digits + string.punctuation)}\n",
    "char2index['//'] = len(char2index) + 1\n",
    "\n",
    "def count_word_number(text, word_count):\n",
    "    for token in text:\n",
    "        if token in word_count:\n",
    "            word_count[token] += 1\n",
    "        else:\n",
    "            word_count[token] = 1\n",
    "\n",
    "def char_tokenizer(text):\n",
    "    char_text = []\n",
    "    for token in text:\n",
    "        token_ = []\n",
    "        if token == '[SEP]':\n",
    "            token_.append(char2index['//'])\n",
    "        else:\n",
    "            for c in token:\n",
    "                if c not in char2index:\n",
    "                    char2index[c] = len(char2index)+1\n",
    "                token_.append(char2index[c])\n",
    "        char_text.append(token_)\n",
    "    return char_text\n",
    "\n",
    "def load_glove(filename):\n",
    "    '''\n",
    "\n",
    "    2018-11-14: add supporting word2vector\n",
    "\n",
    "    '''\n",
    "    word_dic = {}\n",
    "    if 'glove' in filename:\n",
    "        print('\\nload word dictionary starting!')\n",
    "\n",
    "        with open(filename, encoding='utf-8') as fr:\n",
    "            lines = [line for line in fr]\n",
    "            for line in lines:\n",
    "                values = line.split()\n",
    "                word = values[0]\n",
    "                coefs = np.asarray(values[1:], dtype='float32')\n",
    "                word_dic[word] = coefs\n",
    "\n",
    "        print('load word dictionary ending!\\n')\n",
    "    else:\n",
    "        print('\\nload word dictionary starting!')\n",
    "        with open(filename, 'rb') as fr:\n",
    "            word_dic = pkl.load(fr, encoding='bytes')\n",
    "        print('load word dictionary ending!\\n')\n",
    "\n",
    "    return word_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "load word dictionary starting!\n",
      "load word dictionary ending!\n",
      "\n",
      "15dev.xml\n",
      "15test.xml\n",
      "15train.xml\n",
      "16dev.xml\n",
      "16test.xml\n",
      "16train1.xml\n",
      "16train2.xml\n",
      "17test.xml\n"
     ]
    }
   ],
   "source": [
    "word_count_token = {}\n",
    "word_count_lemma = {}\n",
    "word_count_lemma_pro = {}\n",
    "\n",
    "word_dic = load_glove('../assist/glove.vectors.window20.txt')\n",
    "\n",
    "for key in keys_lists:\n",
    "    print(key)\n",
    "    samples = all_samples[key]\n",
    "    samples['q_sub_token'].apply(count_word_number, args=(word_count_token,))\n",
    "    samples['q_body_token'].apply(count_word_number, args=(word_count_token,))\n",
    "    samples['cTEXT_token'].apply(count_word_number, args=(word_count_token,))\n",
    "    \n",
    "    samples['q_sub_lemma'].apply(count_word_number, args=(word_count_lemma,))\n",
    "    samples['q_body_lemma'].apply(count_word_number, args=(word_count_lemma,))\n",
    "    samples['cTEXT_lemma'].apply(count_word_number, args=(word_count_lemma,))\n",
    "    \n",
    "    samples['q_sub_lemma_pro'].apply(count_word_number, args=(word_count_lemma_pro,))\n",
    "    samples['q_body_lemma_pro'].apply(count_word_number, args=(word_count_lemma_pro,))\n",
    "    samples['cTEXT_lemma_pro'].apply(count_word_number, args=(word_count_lemma_pro,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------\n",
      "\t获得word2index并保存, 总词数为66616\n",
      "\t\t总词数为：10000\n",
      "\n",
      "--------------------------------------\n",
      "\t获得word2index并保存, 总词数为62767\n",
      "\t\t总词数为：10000\n",
      "\n",
      "--------------------------------------\n",
      "\t获得word2index并保存, 总词数为41544\n",
      "\t\t总词数为：10000\n"
     ]
    }
   ],
   "source": [
    "savepath = '../assistFORtri'\n",
    "max_vocab = 10000  # 最大词汇数量\n",
    "\n",
    "print('\\n--------------------------------------')\n",
    "word_count_ = sorted(word_count_token.items(), key=lambda x: x[1], reverse=True)\n",
    "print('\\t获得word2index并保存, 总词数为{}'.format(len(word_count_)))\n",
    "with open(os.path.join(savepath, 'word_count_token.json'), 'w') as fw:\n",
    "    json.dump(word_count_, fw)\n",
    "\n",
    "word_count_ = word_count_[:max_vocab]\n",
    "word2index_token = {word: index + 1 for index, (word, _) in enumerate(word_count_)}\n",
    "print('\\t\\t总词数为：%d' % len(word2index_token))\n",
    "with open(os.path.join(savepath, 'word2index_token.json'), 'w') as fw:\n",
    "    json.dump(word2index_token, fw)\n",
    "\n",
    "    \n",
    "print('\\n--------------------------------------')\n",
    "word_count_ = sorted(word_count_lemma.items(), key=lambda x: x[1], reverse=True)\n",
    "print('\\t获得word2index并保存, 总词数为{}'.format(len(word_count_)))\n",
    "with open(os.path.join(savepath, 'word_count_lemma.json'), 'w') as fw:\n",
    "    json.dump(word_count_, fw)\n",
    "\n",
    "word_count_ = word_count_[:max_vocab]\n",
    "word2index_lemma = {word: index + 1 for index, (word, _) in enumerate(word_count_)}\n",
    "print('\\t\\t总词数为：%d' % len(word2index_lemma))\n",
    "with open(os.path.join(savepath, 'word2index_lemma.json'), 'w') as fw:\n",
    "    json.dump(word2index_lemma, fw)\n",
    "\n",
    "    \n",
    "print('\\n--------------------------------------')\n",
    "word_count_ = sorted(word_count_lemma_pro.items(), key=lambda x: x[1], reverse=True)\n",
    "print('\\t获得word2index并保存, 总词数为{}'.format(len(word_count_)))\n",
    "with open(os.path.join(savepath, 'word_count_lemma_pro.json'), 'w') as fw:\n",
    "    json.dump(word_count_, fw)\n",
    "\n",
    "word_count_ = word_count_[:max_vocab]\n",
    "word2index_lemma_pro = {word: index + 1 for index, (word, _) in enumerate(word_count_)}\n",
    "print('\\t\\t总词数为：%d' % len(word2index_lemma_pro))\n",
    "with open(os.path.join(savepath, 'word2index_lemma_pro.json'), 'w') as fw:\n",
    "    json.dump(word2index_lemma_pro, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_id</th>\n",
       "      <th>c_id</th>\n",
       "      <th>q_category</th>\n",
       "      <th>q_subject</th>\n",
       "      <th>q_body</th>\n",
       "      <th>cTEXT</th>\n",
       "      <th>Relevance</th>\n",
       "      <th>q_userid</th>\n",
       "      <th>c_userid</th>\n",
       "      <th>cate_index</th>\n",
       "      <th>...</th>\n",
       "      <th>Rrel_index</th>\n",
       "      <th>q_sub_token</th>\n",
       "      <th>q_body_token</th>\n",
       "      <th>cTEXT_token</th>\n",
       "      <th>q_sub_lemma</th>\n",
       "      <th>q_body_lemma</th>\n",
       "      <th>cTEXT_lemma</th>\n",
       "      <th>q_sub_lemma_pro</th>\n",
       "      <th>q_body_lemma_pro</th>\n",
       "      <th>cTEXT_lemma_pro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q2481</td>\n",
       "      <td>Q2481_C1</td>\n",
       "      <td>Life in Qatar</td>\n",
       "      <td>from DUBAI to QATAR</td>\n",
       "      <td>i am currently working here in dubai and i got...</td>\n",
       "      <td>If you are single then its ok you can enjoy.</td>\n",
       "      <td>PotentiallyUseful</td>\n",
       "      <td>U8902</td>\n",
       "      <td>U7263</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[SEP], from, dubai, to, qatar, [SEP]]</td>\n",
       "      <td>[[SEP], i, am, currently, working, here, in, d...</td>\n",
       "      <td>[[SEP], if, you, are, single, then, its, ok, y...</td>\n",
       "      <td>[[SEP], from, dubai, to, qatar, [SEP]]</td>\n",
       "      <td>[[SEP], i, am, currently, working, here, in, d...</td>\n",
       "      <td>[[SEP], if, you, are, single, then, it, ok, yo...</td>\n",
       "      <td>[[SEP], from, dubai, to, qatar, [SEP]]</td>\n",
       "      <td>[[SEP], i, am, currently, working, here, in, d...</td>\n",
       "      <td>[[SEP], if, you, are, single, then, it, ok, yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2481</td>\n",
       "      <td>Q2481_C2</td>\n",
       "      <td>Life in Qatar</td>\n",
       "      <td>from DUBAI to QATAR</td>\n",
       "      <td>i am currently working here in dubai and i got...</td>\n",
       "      <td>depends on where the accommodation is.. how ma...</td>\n",
       "      <td>Good</td>\n",
       "      <td>U8902</td>\n",
       "      <td>U604</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[SEP], from, dubai, to, qatar, [SEP]]</td>\n",
       "      <td>[[SEP], i, am, currently, working, here, in, d...</td>\n",
       "      <td>[[SEP], depends, on, where, the, accommodation...</td>\n",
       "      <td>[[SEP], from, dubai, to, qatar, [SEP]]</td>\n",
       "      <td>[[SEP], i, am, currently, working, here, in, d...</td>\n",
       "      <td>[[SEP], depends, on, where, the, accommodation...</td>\n",
       "      <td>[[SEP], from, dubai, to, qatar, [SEP]]</td>\n",
       "      <td>[[SEP], i, am, currently, working, here, in, d...</td>\n",
       "      <td>[[SEP], depends, on, where, the, accommodation...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    q_id      c_id     q_category            q_subject  \\\n",
       "0  Q2481  Q2481_C1  Life in Qatar  from DUBAI to QATAR   \n",
       "1  Q2481  Q2481_C2  Life in Qatar  from DUBAI to QATAR   \n",
       "\n",
       "                                              q_body  \\\n",
       "0  i am currently working here in dubai and i got...   \n",
       "1  i am currently working here in dubai and i got...   \n",
       "\n",
       "                                               cTEXT          Relevance  \\\n",
       "0       If you are single then its ok you can enjoy.  PotentiallyUseful   \n",
       "1  depends on where the accommodation is.. how ma...               Good   \n",
       "\n",
       "  q_userid c_userid  cate_index  \\\n",
       "0    U8902    U7263           9   \n",
       "1    U8902     U604           9   \n",
       "\n",
       "                         ...                          Rrel_index  \\\n",
       "0                        ...                                   1   \n",
       "1                        ...                                   0   \n",
       "\n",
       "                              q_sub_token  \\\n",
       "0  [[SEP], from, dubai, to, qatar, [SEP]]   \n",
       "1  [[SEP], from, dubai, to, qatar, [SEP]]   \n",
       "\n",
       "                                        q_body_token  \\\n",
       "0  [[SEP], i, am, currently, working, here, in, d...   \n",
       "1  [[SEP], i, am, currently, working, here, in, d...   \n",
       "\n",
       "                                         cTEXT_token  \\\n",
       "0  [[SEP], if, you, are, single, then, its, ok, y...   \n",
       "1  [[SEP], depends, on, where, the, accommodation...   \n",
       "\n",
       "                              q_sub_lemma  \\\n",
       "0  [[SEP], from, dubai, to, qatar, [SEP]]   \n",
       "1  [[SEP], from, dubai, to, qatar, [SEP]]   \n",
       "\n",
       "                                        q_body_lemma  \\\n",
       "0  [[SEP], i, am, currently, working, here, in, d...   \n",
       "1  [[SEP], i, am, currently, working, here, in, d...   \n",
       "\n",
       "                                         cTEXT_lemma  \\\n",
       "0  [[SEP], if, you, are, single, then, it, ok, yo...   \n",
       "1  [[SEP], depends, on, where, the, accommodation...   \n",
       "\n",
       "                          q_sub_lemma_pro  \\\n",
       "0  [[SEP], from, dubai, to, qatar, [SEP]]   \n",
       "1  [[SEP], from, dubai, to, qatar, [SEP]]   \n",
       "\n",
       "                                    q_body_lemma_pro  \\\n",
       "0  [[SEP], i, am, currently, working, here, in, d...   \n",
       "1  [[SEP], i, am, currently, working, here, in, d...   \n",
       "\n",
       "                                     cTEXT_lemma_pro  \n",
       "0  [[SEP], if, you, are, single, then, it, ok, yo...  \n",
       "1  [[SEP], depends, on, where, the, accommodation...  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_samples['15dev.xml'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15dev.xml\n",
      "15test.xml\n",
      "15train.xml\n",
      "16dev.xml\n",
      "16test.xml\n",
      "16train1.xml\n",
      "16train2.xml\n",
      "17test.xml\n"
     ]
    }
   ],
   "source": [
    "for key in keys_lists:\n",
    "    print(key)\n",
    "    samples = all_samples[key]\n",
    "    token_count = len(word2index_token)\n",
    "    token_replace_func = lambda sent: [word2index_token.get(x, token_count+1) \n",
    "                                       for x in sent]\n",
    "    samples['q_sub_token_index'] = samples['q_sub_token'].apply(token_replace_func)\n",
    "    samples['q_body_token_index'] = samples['q_body_token'].apply(token_replace_func)\n",
    "    samples['cTEXT_token_index'] = samples['cTEXT_token'].apply(token_replace_func)\n",
    "    \n",
    "    lemma_count = len(word2index_lemma)\n",
    "    lemma_replace_func = lambda sent: [word2index_lemma.get(x, lemma_count+1)\n",
    "                                       for x in sent]\n",
    "    samples['q_sub_lemma_index'] = samples['q_sub_lemma'].apply(lemma_replace_func)\n",
    "    samples['q_body_lemma_index'] = samples['q_body_lemma'].apply(lemma_replace_func)\n",
    "    samples['cTEXT_lemma_index'] = samples['cTEXT_lemma'].apply(lemma_replace_func)\n",
    "    \n",
    "    lemma_pro_count = len(word2index_lemma_pro)\n",
    "    lemma_pro_replace_func = lambda sent: [word2index_lemma_pro.get(x, lemma_pro_count+1)\n",
    "                                           for x in sent]\n",
    "    samples['q_sub_lemma_pro_index'] = samples['q_sub_lemma_pro'].apply(lemma_pro_replace_func)\n",
    "    samples['q_sub_lemma_pro_index'] = samples['q_sub_lemma_pro'].apply(lemma_pro_replace_func)\n",
    "    samples['cTEXT_lemma_pro_index'] = samples['cTEXT_lemma_pro'].apply(lemma_pro_replace_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_id</th>\n",
       "      <th>c_id</th>\n",
       "      <th>q_category</th>\n",
       "      <th>q_subject</th>\n",
       "      <th>q_body</th>\n",
       "      <th>cTEXT</th>\n",
       "      <th>Relevance</th>\n",
       "      <th>q_userid</th>\n",
       "      <th>c_userid</th>\n",
       "      <th>cate_index</th>\n",
       "      <th>...</th>\n",
       "      <th>q_body_lemma_pro</th>\n",
       "      <th>cTEXT_lemma_pro</th>\n",
       "      <th>q_sub_token_index</th>\n",
       "      <th>q_body_token_index</th>\n",
       "      <th>cTEXT_token_index</th>\n",
       "      <th>q_sub_lemma_index</th>\n",
       "      <th>q_body_lemma_index</th>\n",
       "      <th>cTEXT_lemma_index</th>\n",
       "      <th>q_sub_lemma_pro_index</th>\n",
       "      <th>cTEXT_lemma_pro_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q2481</td>\n",
       "      <td>Q2481_C1</td>\n",
       "      <td>Life in Qatar</td>\n",
       "      <td>from DUBAI to QATAR</td>\n",
       "      <td>i am currently working here in dubai and i got...</td>\n",
       "      <td>If you are single then its ok you can enjoy.</td>\n",
       "      <td>PotentiallyUseful</td>\n",
       "      <td>U8902</td>\n",
       "      <td>U7263</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>[[SEP], i, am, currently, working, here, in, d...</td>\n",
       "      <td>[[SEP], if, you, are, single, then, it, ok, yo...</td>\n",
       "      <td>[1, 42, 210, 5, 23, 1]</td>\n",
       "      <td>[1, 6, 58, 434, 151, 50, 9, 210, 10, 6, 125, 7...</td>\n",
       "      <td>[1, 24, 12, 21, 426, 119, 97, 345, 12, 18, 550...</td>\n",
       "      <td>[1, 42, 219, 5, 23, 1]</td>\n",
       "      <td>[1, 6, 57, 457, 156, 50, 9, 219, 10, 6, 132, 7...</td>\n",
       "      <td>[1, 24, 12, 21, 429, 124, 14, 350, 12, 18, 572...</td>\n",
       "      <td>[1, 42, 218, 5, 23, 1]</td>\n",
       "      <td>[1, 24, 13, 20, 421, 122, 15, 308, 13, 17, 569...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2481</td>\n",
       "      <td>Q2481_C2</td>\n",
       "      <td>Life in Qatar</td>\n",
       "      <td>from DUBAI to QATAR</td>\n",
       "      <td>i am currently working here in dubai and i got...</td>\n",
       "      <td>depends on where the accommodation is.. how ma...</td>\n",
       "      <td>Good</td>\n",
       "      <td>U8902</td>\n",
       "      <td>U604</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>[[SEP], i, am, currently, working, here, in, d...</td>\n",
       "      <td>[[SEP], depends, on, where, the, accommodation...</td>\n",
       "      <td>[1, 42, 210, 5, 23, 1]</td>\n",
       "      <td>[1, 6, 58, 434, 151, 50, 9, 210, 10, 6, 125, 7...</td>\n",
       "      <td>[1, 634, 29, 60, 4, 682, 5502, 48, 129, 110, 3...</td>\n",
       "      <td>[1, 42, 219, 5, 23, 1]</td>\n",
       "      <td>[1, 6, 57, 457, 156, 50, 9, 219, 10, 6, 132, 7...</td>\n",
       "      <td>[1, 655, 29, 59, 4, 668, 5050, 48, 134, 111, 3...</td>\n",
       "      <td>[1, 42, 218, 5, 23, 1]</td>\n",
       "      <td>[1, 659, 28, 60, 3, 663, 11, 2, 49, 136, 111, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    q_id      c_id     q_category            q_subject  \\\n",
       "0  Q2481  Q2481_C1  Life in Qatar  from DUBAI to QATAR   \n",
       "1  Q2481  Q2481_C2  Life in Qatar  from DUBAI to QATAR   \n",
       "\n",
       "                                              q_body  \\\n",
       "0  i am currently working here in dubai and i got...   \n",
       "1  i am currently working here in dubai and i got...   \n",
       "\n",
       "                                               cTEXT          Relevance  \\\n",
       "0       If you are single then its ok you can enjoy.  PotentiallyUseful   \n",
       "1  depends on where the accommodation is.. how ma...               Good   \n",
       "\n",
       "  q_userid c_userid  cate_index  \\\n",
       "0    U8902    U7263           9   \n",
       "1    U8902     U604           9   \n",
       "\n",
       "                         ...                          \\\n",
       "0                        ...                           \n",
       "1                        ...                           \n",
       "\n",
       "                                    q_body_lemma_pro  \\\n",
       "0  [[SEP], i, am, currently, working, here, in, d...   \n",
       "1  [[SEP], i, am, currently, working, here, in, d...   \n",
       "\n",
       "                                     cTEXT_lemma_pro       q_sub_token_index  \\\n",
       "0  [[SEP], if, you, are, single, then, it, ok, yo...  [1, 42, 210, 5, 23, 1]   \n",
       "1  [[SEP], depends, on, where, the, accommodation...  [1, 42, 210, 5, 23, 1]   \n",
       "\n",
       "                                  q_body_token_index  \\\n",
       "0  [1, 6, 58, 434, 151, 50, 9, 210, 10, 6, 125, 7...   \n",
       "1  [1, 6, 58, 434, 151, 50, 9, 210, 10, 6, 125, 7...   \n",
       "\n",
       "                                   cTEXT_token_index       q_sub_lemma_index  \\\n",
       "0  [1, 24, 12, 21, 426, 119, 97, 345, 12, 18, 550...  [1, 42, 219, 5, 23, 1]   \n",
       "1  [1, 634, 29, 60, 4, 682, 5502, 48, 129, 110, 3...  [1, 42, 219, 5, 23, 1]   \n",
       "\n",
       "                                  q_body_lemma_index  \\\n",
       "0  [1, 6, 57, 457, 156, 50, 9, 219, 10, 6, 132, 7...   \n",
       "1  [1, 6, 57, 457, 156, 50, 9, 219, 10, 6, 132, 7...   \n",
       "\n",
       "                                   cTEXT_lemma_index   q_sub_lemma_pro_index  \\\n",
       "0  [1, 24, 12, 21, 429, 124, 14, 350, 12, 18, 572...  [1, 42, 218, 5, 23, 1]   \n",
       "1  [1, 655, 29, 59, 4, 668, 5050, 48, 134, 111, 3...  [1, 42, 218, 5, 23, 1]   \n",
       "\n",
       "                               cTEXT_lemma_pro_index  \n",
       "0  [1, 24, 13, 20, 421, 122, 15, 308, 13, 17, 569...  \n",
       "1  [1, 659, 28, 60, 3, 663, 11, 2, 49, 136, 111, ...  \n",
       "\n",
       "[2 rows x 29 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_samples['15dev.xml'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------\n",
      "\t作嵌入矩阵并保存\n",
      "\n",
      "\n",
      "--------------------------------------\n",
      "\t作嵌入矩阵并保存\n",
      "\n",
      "\n",
      "--------------------------------------\n",
      "\t作嵌入矩阵并保存\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\n--------------------------------------')\n",
    "print('\\t作嵌入矩阵并保存\\n')\n",
    "dim = word_dic['word'].shape[0]\n",
    "embedding_matrix_token = np.random.randn(len(word2index_token) + 1, dim)\n",
    "embedding_matrix_token[0] = np.zeros((dim, ), dtype='float32')\n",
    "for word, index in word2index_token.items():\n",
    "    if word in word_dic:\n",
    "        embedding_matrix_token[index] = word_dic[word]\n",
    "with open(os.path.join(savepath, 'embedding_matrix_token.pkl'), 'wb') as fw:\n",
    "    pkl.dump(embedding_matrix_token, fw)\n",
    "\n",
    "    \n",
    "print('\\n--------------------------------------')\n",
    "print('\\t作嵌入矩阵并保存\\n')\n",
    "embedding_matrix_lemma = np.random.randn(len(word2index_lemma) + 1, dim)\n",
    "embedding_matrix_lemma[0] = np.zeros((dim, ), dtype='float32')\n",
    "for word, index in word2index_lemma.items():\n",
    "    if word in word_dic:\n",
    "        embedding_matrix_lemma[index] = word_dic[word]\n",
    "with open(os.path.join(savepath, 'embedding_matrix_lemma.pkl'), 'wb') as fw:\n",
    "    pkl.dump(embedding_matrix_lemma, fw)\n",
    "\n",
    "    \n",
    "print('\\n--------------------------------------')\n",
    "print('\\t作嵌入矩阵并保存\\n')\n",
    "embedding_matrix_lemma_pro = np.random.randn(len(word2index_lemma_pro) + 1, dim)\n",
    "embedding_matrix_lemma_pro[0] = np.zeros((dim, ), dtype='float32')\n",
    "for word, index in word2index_lemma_pro.items():\n",
    "    if word in word_dic:\n",
    "        embedding_matrix_lemma_pro[index] = word_dic[word]\n",
    "with open(os.path.join(savepath, 'embedding_matrix_lemma_pro.pkl'), 'wb') as fw:\n",
    "    pkl.dump(embedding_matrix_lemma_pro, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15dev.xml\n",
      "15test.xml\n",
      "15train.xml\n",
      "16dev.xml\n",
      "16test.xml\n",
      "16train1.xml\n",
      "16train2.xml\n",
      "17test.xml\n"
     ]
    }
   ],
   "source": [
    "for key in keys_lists:\n",
    "    print(key)\n",
    "    samples = all_samples[key]\n",
    "    process_char = lambda sent: pad_sequences(char_tokenizer(sent), maxlen=20, padding='post', truncating='post')\n",
    "    samples['q_sub_token_char_index'] = samples['q_sub_token'].apply(process_char)\n",
    "    samples['q_body_token_char_index'] = samples['q_body_token'].apply(process_char)\n",
    "    samples['cTEXT_token_char_index'] = samples['cTEXT_token'].apply(process_char)\n",
    "    \n",
    "    samples['q_sub_lemma_char_index'] = samples['q_sub_lemma'].apply(process_char)\n",
    "    samples['q_body_lemma_char_index'] = samples['q_body_lemma'].apply(process_char)\n",
    "    samples['cTEXT_lemma_char_index'] = samples['cTEXT_lemma'].apply(process_char)\n",
    "    \n",
    "    samples['q_sub_lemma_pro_char_index'] = samples['q_sub_lemma_pro'].apply(process_char)\n",
    "    samples['q_body_lemma_pro_char_index'] = samples['q_body_lemma_pro'].apply(process_char)\n",
    "    samples['cTEXT_lemma_pro_char_index'] = samples['cTEXT_lemma_pro'].apply(process_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_id</th>\n",
       "      <th>c_id</th>\n",
       "      <th>q_category</th>\n",
       "      <th>q_subject</th>\n",
       "      <th>q_body</th>\n",
       "      <th>cTEXT</th>\n",
       "      <th>Relevance</th>\n",
       "      <th>q_userid</th>\n",
       "      <th>c_userid</th>\n",
       "      <th>cate_index</th>\n",
       "      <th>...</th>\n",
       "      <th>cTEXT_lemma_pro_index</th>\n",
       "      <th>q_sub_token_char_index</th>\n",
       "      <th>q_body_token_char_index</th>\n",
       "      <th>cTEXT_token_char_index</th>\n",
       "      <th>q_sub_lemma_char_index</th>\n",
       "      <th>q_body_lemma_char_index</th>\n",
       "      <th>cTEXT_lemma_char_index</th>\n",
       "      <th>q_sub_lemma_pro_char_index</th>\n",
       "      <th>q_body_lemma_pro_char_index</th>\n",
       "      <th>cTEXT_lemma_pro_char_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q2481</td>\n",
       "      <td>Q2481_C1</td>\n",
       "      <td>Life in Qatar</td>\n",
       "      <td>from DUBAI to QATAR</td>\n",
       "      <td>i am currently working here in dubai and i got...</td>\n",
       "      <td>If you are single then its ok you can enjoy.</td>\n",
       "      <td>PotentiallyUseful</td>\n",
       "      <td>U8902</td>\n",
       "      <td>U7263</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>[1, 24, 13, 20, 421, 122, 15, 308, 13, 17, 569...</td>\n",
       "      <td>[[95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[[95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[[95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[[95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[[95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[[95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[[95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[[95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[[95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2481</td>\n",
       "      <td>Q2481_C2</td>\n",
       "      <td>Life in Qatar</td>\n",
       "      <td>from DUBAI to QATAR</td>\n",
       "      <td>i am currently working here in dubai and i got...</td>\n",
       "      <td>depends on where the accommodation is.. how ma...</td>\n",
       "      <td>Good</td>\n",
       "      <td>U8902</td>\n",
       "      <td>U604</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>[1, 659, 28, 60, 3, 663, 11, 2, 49, 136, 111, ...</td>\n",
       "      <td>[[95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[[95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[[95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[[95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[[95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[[95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[[95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[[95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[[95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    q_id      c_id     q_category            q_subject  \\\n",
       "0  Q2481  Q2481_C1  Life in Qatar  from DUBAI to QATAR   \n",
       "1  Q2481  Q2481_C2  Life in Qatar  from DUBAI to QATAR   \n",
       "\n",
       "                                              q_body  \\\n",
       "0  i am currently working here in dubai and i got...   \n",
       "1  i am currently working here in dubai and i got...   \n",
       "\n",
       "                                               cTEXT          Relevance  \\\n",
       "0       If you are single then its ok you can enjoy.  PotentiallyUseful   \n",
       "1  depends on where the accommodation is.. how ma...               Good   \n",
       "\n",
       "  q_userid c_userid  cate_index  \\\n",
       "0    U8902    U7263           9   \n",
       "1    U8902     U604           9   \n",
       "\n",
       "                         ...                          \\\n",
       "0                        ...                           \n",
       "1                        ...                           \n",
       "\n",
       "                               cTEXT_lemma_pro_index  \\\n",
       "0  [1, 24, 13, 20, 421, 122, 15, 308, 13, 17, 569...   \n",
       "1  [1, 659, 28, 60, 3, 663, 11, 2, 49, 136, 111, ...   \n",
       "\n",
       "                              q_sub_token_char_index  \\\n",
       "0  [[95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "1  [[95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "\n",
       "                             q_body_token_char_index  \\\n",
       "0  [[95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "1  [[95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "\n",
       "                              cTEXT_token_char_index  \\\n",
       "0  [[95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "1  [[95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "\n",
       "                              q_sub_lemma_char_index  \\\n",
       "0  [[95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "1  [[95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "\n",
       "                             q_body_lemma_char_index  \\\n",
       "0  [[95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "1  [[95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "\n",
       "                              cTEXT_lemma_char_index  \\\n",
       "0  [[95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "1  [[95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "\n",
       "                          q_sub_lemma_pro_char_index  \\\n",
       "0  [[95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "1  [[95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "\n",
       "                         q_body_lemma_pro_char_index  \\\n",
       "0  [[95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "1  [[95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "\n",
       "                          cTEXT_lemma_pro_char_index  \n",
       "0  [[95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...  \n",
       "1  [[95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...  \n",
       "\n",
       "[2 rows x 38 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_samples['15dev.xml'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------\n",
      "\tsave char2index\n",
      "\t\tthe number of charactor：334\n"
     ]
    }
   ],
   "source": [
    "print('\\n--------------------------------------')\n",
    "print('\\tsave char2index')\n",
    "print('\\t\\tthe number of charactor：%d' % len(char2index))\n",
    "with open(os.path.join(savepath, 'char2index.json'), 'w') as fw:\n",
    "    json.dump(char2index, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15dev.xml\n",
      "15test.xml\n",
      "15train.xml\n",
      "16dev.xml\n",
      "16test.xml\n",
      "16train1.xml\n",
      "16train2.xml\n",
      "17test.xml\n"
     ]
    }
   ],
   "source": [
    "for key in keys_lists:\n",
    "    print(key)\n",
    "    samples = all_samples[key]\n",
    "    \n",
    "    samples['q_sub_len'] = samples['q_sub_token'].apply(len)\n",
    "    samples['q_body_len'] = samples['q_body_token'].apply(len)\n",
    "    samples['cTEXT_len'] = samples['cTEXT_token'].apply(len)\n",
    "    \n",
    "    samples['q_sub_pro_len'] = samples['q_sub_lemma_pro'].apply(len)\n",
    "    samples['q_body_pro_len'] = samples['q_body_lemma_pro'].apply(len)\n",
    "    samples['cTEXT_pro_len'] = samples['cTEXT_lemma_pro'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 15dev.xml\n",
      "------  q_sub length -------\n",
      "count    1529.000000\n",
      "mean        7.604971\n",
      "std         3.755223\n",
      "min         3.000000\n",
      "50%         7.000000\n",
      "80%        11.000000\n",
      "90%        12.200000\n",
      "95%        14.000000\n",
      "98%        18.000000\n",
      "max        23.000000\n",
      "Name: q_sub_len, dtype: float64\n",
      "------  q_body length -------\n",
      "count    1529.000000\n",
      "mean       42.107260\n",
      "std        21.675353\n",
      "min         5.000000\n",
      "50%        39.000000\n",
      "80%        63.000000\n",
      "90%        75.000000\n",
      "95%        81.000000\n",
      "98%        85.000000\n",
      "max       106.000000\n",
      "Name: q_body_len, dtype: float64\n",
      "------  cTEXT length -------\n",
      "count    1529.000000\n",
      "mean       36.385219\n",
      "std        48.396906\n",
      "min         3.000000\n",
      "50%        25.000000\n",
      "80%        52.000000\n",
      "90%        77.000000\n",
      "95%        98.000000\n",
      "98%       132.000000\n",
      "max      1348.000000\n",
      "Name: cTEXT_len, dtype: float64\n",
      "==================================================================\n",
      "------  q_sub lemma pro length -------\n",
      "count    1529.000000\n",
      "mean        7.647482\n",
      "std         3.789192\n",
      "min         3.000000\n",
      "50%         7.000000\n",
      "80%        10.000000\n",
      "90%        12.000000\n",
      "95%        15.000000\n",
      "98%        17.000000\n",
      "max        23.000000\n",
      "Name: q_sub_pro_len, dtype: float64\n",
      "------  q_body lemma pro length -------\n",
      "count    1529.000000\n",
      "mean       42.677567\n",
      "std        22.032788\n",
      "min         6.000000\n",
      "50%        40.000000\n",
      "80%        64.000000\n",
      "90%        75.000000\n",
      "95%        82.000000\n",
      "98%        86.440000\n",
      "max       112.000000\n",
      "Name: q_body_pro_len, dtype: float64\n",
      "------  cTEXT lemma pro length -------\n",
      "count    1529.000000\n",
      "mean       35.523872\n",
      "std        48.462712\n",
      "min         3.000000\n",
      "50%        24.000000\n",
      "80%        51.000000\n",
      "90%        74.000000\n",
      "95%        97.000000\n",
      "98%       132.880000\n",
      "max      1358.000000\n",
      "Name: cTEXT_pro_len, dtype: float64\n",
      "\n",
      "\n",
      " 15test.xml\n",
      "------  q_sub length -------\n",
      "count    1876.000000\n",
      "mean        7.919510\n",
      "std         3.886856\n",
      "min         3.000000\n",
      "50%         7.000000\n",
      "80%        11.000000\n",
      "90%        12.000000\n",
      "95%        14.000000\n",
      "98%        19.000000\n",
      "max        29.000000\n",
      "Name: q_sub_len, dtype: float64\n",
      "------  q_body length -------\n",
      "count    1876.000000\n",
      "mean       40.870469\n",
      "std        23.513372\n",
      "min         3.000000\n",
      "50%        36.000000\n",
      "80%        63.000000\n",
      "90%        72.000000\n",
      "95%        85.000000\n",
      "98%        93.000000\n",
      "max       107.000000\n",
      "Name: q_body_len, dtype: float64\n",
      "------  cTEXT length -------\n",
      "count    1876.000000\n",
      "mean       37.650320\n",
      "std        40.808304\n",
      "min         3.000000\n",
      "50%        25.000000\n",
      "80%        55.000000\n",
      "90%        82.000000\n",
      "95%       108.000000\n",
      "98%       143.500000\n",
      "max       658.000000\n",
      "Name: cTEXT_len, dtype: float64\n",
      "==================================================================\n",
      "------  q_sub lemma pro length -------\n",
      "count    1876.000000\n",
      "mean        7.860341\n",
      "std         3.859769\n",
      "min         3.000000\n",
      "50%         7.000000\n",
      "80%        10.000000\n",
      "90%        12.000000\n",
      "95%        14.000000\n",
      "98%        17.500000\n",
      "max        28.000000\n",
      "Name: q_sub_pro_len, dtype: float64\n",
      "------  q_body lemma pro length -------\n",
      "count    1876.000000\n",
      "mean       41.388060\n",
      "std        24.211793\n",
      "min         3.000000\n",
      "50%        36.000000\n",
      "80%        65.000000\n",
      "90%        75.000000\n",
      "95%        86.000000\n",
      "98%        94.500000\n",
      "max       107.000000\n",
      "Name: q_body_pro_len, dtype: float64\n",
      "------  cTEXT lemma pro length -------\n",
      "count    1876.000000\n",
      "mean       36.092751\n",
      "std        40.638949\n",
      "min         3.000000\n",
      "50%        24.000000\n",
      "80%        52.000000\n",
      "90%        77.500000\n",
      "95%       107.250000\n",
      "98%       144.000000\n",
      "max       684.000000\n",
      "Name: cTEXT_pro_len, dtype: float64\n",
      "\n",
      "\n",
      " 15train.xml\n",
      "------  q_sub length -------\n",
      "count    14893.000000\n",
      "mean         8.115961\n",
      "std          3.822414\n",
      "min          2.000000\n",
      "50%          8.000000\n",
      "80%         11.000000\n",
      "90%         13.000000\n",
      "95%         15.000000\n",
      "98%         19.000000\n",
      "max         28.000000\n",
      "Name: q_sub_len, dtype: float64\n",
      "------  q_body length -------\n",
      "count    14893.000000\n",
      "mean        41.628013\n",
      "std         21.419466\n",
      "min          3.000000\n",
      "50%         38.000000\n",
      "80%         61.000000\n",
      "90%         74.000000\n",
      "95%         81.000000\n",
      "98%         90.000000\n",
      "max        110.000000\n",
      "Name: q_body_len, dtype: float64\n",
      "------  cTEXT length -------\n",
      "count    14893.000000\n",
      "mean        36.946485\n",
      "std         43.263924\n",
      "min          3.000000\n",
      "50%         25.000000\n",
      "80%         53.000000\n",
      "90%         77.000000\n",
      "95%        106.000000\n",
      "98%        152.000000\n",
      "max       1755.000000\n",
      "Name: cTEXT_len, dtype: float64\n",
      "==================================================================\n",
      "------  q_sub lemma pro length -------\n",
      "count    14893.000000\n",
      "mean         8.109985\n",
      "std          3.806668\n",
      "min          2.000000\n",
      "50%          7.000000\n",
      "80%         11.000000\n",
      "90%         13.000000\n",
      "95%         15.000000\n",
      "98%         19.000000\n",
      "max         29.000000\n",
      "Name: q_sub_pro_len, dtype: float64\n",
      "------  q_body lemma pro length -------\n",
      "count    14893.000000\n",
      "mean        42.002484\n",
      "std         21.775601\n",
      "min          3.000000\n",
      "50%         38.000000\n",
      "80%         62.000000\n",
      "90%         75.000000\n",
      "95%         82.000000\n",
      "98%         90.000000\n",
      "max        109.000000\n",
      "Name: q_body_pro_len, dtype: float64\n",
      "------  cTEXT lemma pro length -------\n",
      "count    14893.000000\n",
      "mean        35.998657\n",
      "std         41.255902\n",
      "min          2.000000\n",
      "50%         24.000000\n",
      "80%         51.000000\n",
      "90%         74.000000\n",
      "95%        104.000000\n",
      "98%        153.000000\n",
      "max       1208.000000\n",
      "Name: cTEXT_pro_len, dtype: float64\n",
      "\n",
      "\n",
      " 16dev.xml\n",
      "------  q_sub length -------\n",
      "count    2440.000000\n",
      "mean        8.045082\n",
      "std         3.530749\n",
      "min         3.000000\n",
      "50%         7.000000\n",
      "80%        11.000000\n",
      "90%        12.000000\n",
      "95%        14.000000\n",
      "98%        19.000000\n",
      "max        26.000000\n",
      "Name: q_sub_len, dtype: float64\n",
      "------  q_body length -------\n",
      "count    2440.000000\n",
      "mean       48.536885\n",
      "std        25.243275\n",
      "min         2.000000\n",
      "50%        46.000000\n",
      "80%        72.000000\n",
      "90%        86.000000\n",
      "95%        94.000000\n",
      "98%       102.000000\n",
      "max       109.000000\n",
      "Name: q_body_len, dtype: float64\n",
      "------  cTEXT length -------\n",
      "count    2440.000000\n",
      "mean       38.192623\n",
      "std        37.544624\n",
      "min         3.000000\n",
      "50%        26.000000\n",
      "80%        55.000000\n",
      "90%        83.000000\n",
      "95%       113.000000\n",
      "98%       164.220000\n",
      "max       236.000000\n",
      "Name: cTEXT_len, dtype: float64\n",
      "==================================================================\n",
      "------  q_sub lemma pro length -------\n",
      "count    2440.000000\n",
      "mean        7.946721\n",
      "std         3.362911\n",
      "min         3.000000\n",
      "50%         7.000000\n",
      "80%        11.000000\n",
      "90%        12.000000\n",
      "95%        14.000000\n",
      "98%        16.000000\n",
      "max        26.000000\n",
      "Name: q_sub_pro_len, dtype: float64\n",
      "------  q_body lemma pro length -------\n",
      "count    2440.000000\n",
      "mean       48.614754\n",
      "std        25.579450\n",
      "min         2.000000\n",
      "50%        46.000000\n",
      "80%        73.000000\n",
      "90%        87.000000\n",
      "95%        93.000000\n",
      "98%       104.000000\n",
      "max       109.000000\n",
      "Name: q_body_pro_len, dtype: float64\n",
      "------  cTEXT lemma pro length -------\n",
      "count    2440.000000\n",
      "mean       38.801230\n",
      "std        38.293651\n",
      "min         3.000000\n",
      "50%        27.000000\n",
      "80%        56.000000\n",
      "90%        84.000000\n",
      "95%       114.050000\n",
      "98%       167.220000\n",
      "max       279.000000\n",
      "Name: cTEXT_pro_len, dtype: float64\n",
      "\n",
      "\n",
      " 16test.xml\n",
      "------  q_sub length -------\n",
      "count    3270.000000\n",
      "mean        8.171254\n",
      "std         3.658908\n",
      "min         3.000000\n",
      "50%         8.000000\n",
      "80%        11.000000\n",
      "90%        12.000000\n",
      "95%        15.000000\n",
      "98%        19.000000\n",
      "max        24.000000\n",
      "Name: q_sub_len, dtype: float64\n",
      "------  q_body length -------\n",
      "count    3270.000000\n",
      "mean       49.899083\n",
      "std        26.066230\n",
      "min         2.000000\n",
      "50%        48.000000\n",
      "80%        76.000000\n",
      "90%        86.000000\n",
      "95%        92.000000\n",
      "98%       102.000000\n",
      "max       116.000000\n",
      "Name: q_body_len, dtype: float64\n",
      "------  cTEXT length -------\n",
      "count    3270.000000\n",
      "mean       39.280122\n",
      "std        37.190988\n",
      "min         3.000000\n",
      "50%        27.000000\n",
      "80%        59.000000\n",
      "90%        84.000000\n",
      "95%       115.000000\n",
      "98%       159.620000\n",
      "max       248.000000\n",
      "Name: cTEXT_len, dtype: float64\n",
      "==================================================================\n",
      "------  q_sub lemma pro length -------\n",
      "count    3270.000000\n",
      "mean        8.137615\n",
      "std         3.622103\n",
      "min         3.000000\n",
      "50%         8.000000\n",
      "80%        11.000000\n",
      "90%        12.000000\n",
      "95%        15.000000\n",
      "98%        18.000000\n",
      "max        25.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: q_sub_pro_len, dtype: float64\n",
      "------  q_body lemma pro length -------\n",
      "count    3270.000000\n",
      "mean       50.097859\n",
      "std        26.400617\n",
      "min         2.000000\n",
      "50%        48.000000\n",
      "80%        77.000000\n",
      "90%        87.000000\n",
      "95%        94.000000\n",
      "98%       100.000000\n",
      "max       112.000000\n",
      "Name: q_body_pro_len, dtype: float64\n",
      "------  cTEXT lemma pro length -------\n",
      "count    3270.000000\n",
      "mean       39.858716\n",
      "std        37.750403\n",
      "min         3.000000\n",
      "50%        28.000000\n",
      "80%        60.000000\n",
      "90%        86.000000\n",
      "95%       115.000000\n",
      "98%       161.000000\n",
      "max       238.000000\n",
      "Name: cTEXT_pro_len, dtype: float64\n",
      "\n",
      "\n",
      " 16train1.xml\n",
      "------  q_sub length -------\n",
      "count    14110.000000\n",
      "mean         8.439405\n",
      "std          3.583256\n",
      "min          3.000000\n",
      "50%          8.000000\n",
      "80%         11.000000\n",
      "90%         13.000000\n",
      "95%         15.000000\n",
      "98%         18.000000\n",
      "max         28.000000\n",
      "Name: q_sub_len, dtype: float64\n",
      "------  q_body length -------\n",
      "count    14110.000000\n",
      "mean        52.907158\n",
      "std         26.236666\n",
      "min          2.000000\n",
      "50%         52.000000\n",
      "80%         78.000000\n",
      "90%         89.000000\n",
      "95%         97.000000\n",
      "98%        102.000000\n",
      "max        119.000000\n",
      "Name: q_body_len, dtype: float64\n",
      "------  cTEXT length -------\n",
      "count    14110.000000\n",
      "mean        43.556839\n",
      "std         40.858553\n",
      "min          3.000000\n",
      "50%         30.000000\n",
      "80%         64.000000\n",
      "90%         95.000000\n",
      "95%        129.000000\n",
      "98%        182.000000\n",
      "max        270.000000\n",
      "Name: cTEXT_len, dtype: float64\n",
      "==================================================================\n",
      "------  q_sub lemma pro length -------\n",
      "count    14110.000000\n",
      "mean         8.377746\n",
      "std          3.492513\n",
      "min          3.000000\n",
      "50%          8.000000\n",
      "80%         11.000000\n",
      "90%         12.000000\n",
      "95%         15.000000\n",
      "98%         17.000000\n",
      "max         29.000000\n",
      "Name: q_sub_pro_len, dtype: float64\n",
      "------  q_body lemma pro length -------\n",
      "count    14110.000000\n",
      "mean        53.072289\n",
      "std         26.642734\n",
      "min          2.000000\n",
      "50%         52.000000\n",
      "80%         79.000000\n",
      "90%         90.000000\n",
      "95%         97.000000\n",
      "98%        102.000000\n",
      "max        116.000000\n",
      "Name: q_body_pro_len, dtype: float64\n",
      "------  cTEXT lemma pro length -------\n",
      "count    14110.000000\n",
      "mean        44.267257\n",
      "std         41.480170\n",
      "min          3.000000\n",
      "50%         31.000000\n",
      "80%         65.000000\n",
      "90%         97.000000\n",
      "95%        131.000000\n",
      "98%        183.820000\n",
      "max        258.000000\n",
      "Name: cTEXT_pro_len, dtype: float64\n",
      "\n",
      "\n",
      " 16train2.xml\n",
      "------  q_sub length -------\n",
      "count    3790.000000\n",
      "mean        8.538259\n",
      "std         4.076400\n",
      "min         3.000000\n",
      "50%         8.000000\n",
      "80%        11.000000\n",
      "90%        14.000000\n",
      "95%        16.000000\n",
      "98%        21.000000\n",
      "max        30.000000\n",
      "Name: q_sub_len, dtype: float64\n",
      "------  q_body length -------\n",
      "count    3790.000000\n",
      "mean       50.174142\n",
      "std        27.153732\n",
      "min         2.000000\n",
      "50%        50.000000\n",
      "80%        75.000000\n",
      "90%        87.000000\n",
      "95%        95.100000\n",
      "98%       100.000000\n",
      "max       124.000000\n",
      "Name: q_body_len, dtype: float64\n",
      "------  cTEXT length -------\n",
      "count    3790.000000\n",
      "mean       38.905277\n",
      "std        36.028767\n",
      "min         3.000000\n",
      "50%        28.000000\n",
      "80%        58.000000\n",
      "90%        82.000000\n",
      "95%       111.000000\n",
      "98%       149.000000\n",
      "max       234.000000\n",
      "Name: cTEXT_len, dtype: float64\n",
      "==================================================================\n",
      "------  q_sub lemma pro length -------\n",
      "count    3790.000000\n",
      "mean        8.448549\n",
      "std         3.997804\n",
      "min         3.000000\n",
      "50%         8.000000\n",
      "80%        11.000000\n",
      "90%        14.000000\n",
      "95%        16.000000\n",
      "98%        21.000000\n",
      "max        28.000000\n",
      "Name: q_sub_pro_len, dtype: float64\n",
      "------  q_body lemma pro length -------\n",
      "count    3790.000000\n",
      "mean       50.160950\n",
      "std        27.349395\n",
      "min         2.000000\n",
      "50%        49.000000\n",
      "80%        77.000000\n",
      "90%        88.000000\n",
      "95%        93.550000\n",
      "98%       105.000000\n",
      "max       124.000000\n",
      "Name: q_body_pro_len, dtype: float64\n",
      "------  cTEXT lemma pro length -------\n",
      "count    3790.000000\n",
      "mean       39.333245\n",
      "std        36.423922\n",
      "min         3.000000\n",
      "50%        28.000000\n",
      "80%        59.000000\n",
      "90%        83.000000\n",
      "95%       113.000000\n",
      "98%       150.440000\n",
      "max       238.000000\n",
      "Name: cTEXT_pro_len, dtype: float64\n",
      "\n",
      "\n",
      " 17test.xml\n",
      "------  q_sub length -------\n",
      "count    2930.000000\n",
      "mean        7.767918\n",
      "std         3.451967\n",
      "min         3.000000\n",
      "50%         7.000000\n",
      "80%        10.000000\n",
      "90%        12.000000\n",
      "95%        13.000000\n",
      "98%        17.000000\n",
      "max        24.000000\n",
      "Name: q_sub_len, dtype: float64\n",
      "------  q_body length -------\n",
      "count    2930.000000\n",
      "mean       56.010239\n",
      "std        29.278391\n",
      "min         6.000000\n",
      "50%        50.000000\n",
      "80%        86.000000\n",
      "90%       100.000000\n",
      "95%       106.000000\n",
      "98%       111.000000\n",
      "max       124.000000\n",
      "Name: q_body_len, dtype: float64\n",
      "------  cTEXT length -------\n",
      "count    2930.000000\n",
      "mean       41.458362\n",
      "std        40.259373\n",
      "min         3.000000\n",
      "50%        29.000000\n",
      "80%        60.000000\n",
      "90%        90.100000\n",
      "95%       122.000000\n",
      "98%       164.000000\n",
      "max       414.000000\n",
      "Name: cTEXT_len, dtype: float64\n",
      "==================================================================\n",
      "------  q_sub lemma pro length -------\n",
      "count    2930.000000\n",
      "mean        7.706485\n",
      "std         3.445304\n",
      "min         3.000000\n",
      "50%         7.000000\n",
      "80%        10.000000\n",
      "90%        12.000000\n",
      "95%        14.000000\n",
      "98%        18.000000\n",
      "max        24.000000\n",
      "Name: q_sub_pro_len, dtype: float64\n",
      "------  q_body lemma pro length -------\n",
      "count    2930.000000\n",
      "mean       56.604096\n",
      "std        29.814155\n",
      "min         6.000000\n",
      "50%        52.000000\n",
      "80%        90.000000\n",
      "90%       102.000000\n",
      "95%       108.000000\n",
      "98%       113.000000\n",
      "max       126.000000\n",
      "Name: q_body_pro_len, dtype: float64\n",
      "------  cTEXT lemma pro length -------\n",
      "count    2930.000000\n",
      "mean       42.364505\n",
      "std        41.605960\n",
      "min         3.000000\n",
      "50%        29.000000\n",
      "80%        62.000000\n",
      "90%        92.000000\n",
      "95%       124.000000\n",
      "98%       169.420000\n",
      "max       450.000000\n",
      "Name: cTEXT_pro_len, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for key in keys_lists:\n",
    "    print('\\n\\n', key)\n",
    "    samples = all_samples[key]\n",
    "    print('------  q_sub length -------')\n",
    "    print(samples['q_sub_len'].describe([0.8, 0.9, 0.95, 0.98]))\n",
    "    print('------  q_body length -------')\n",
    "    print(samples['q_body_len'].describe([0.8, 0.9, 0.95, 0.98]))\n",
    "    print('------  cTEXT length -------')\n",
    "    print(samples['cTEXT_len'].describe([0.8, 0.9, 0.95, 0.98]))\n",
    "    \n",
    "    print(\"==================================================================\")\n",
    "    print('------  q_sub lemma pro length -------')\n",
    "    print(samples['q_sub_pro_len'].describe([0.8, 0.9, 0.95, 0.98]))\n",
    "    print('------  q_body lemma pro length -------')\n",
    "    print(samples['q_body_pro_len'].describe([0.8, 0.9, 0.95, 0.98]))\n",
    "    print('------  cTEXT lemma pro length -------')\n",
    "    print(samples['cTEXT_pro_len'].describe([0.8, 0.9, 0.95, 0.98]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('../data', 'datasetFORtri.pkl'), 'wb') as fw:\n",
    "    pkl.dump(all_samples, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
